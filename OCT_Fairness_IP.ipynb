{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "#fold=1\n",
    "#dataset='nursery' #'NHPA'\n",
    "#d = 2# depth\n",
    "#epsilon=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAIRNESS SETS and PARAMS\n",
    "\n",
    "#sensitive_features=[5]#[38,39,40,41,42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cython Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pricing_Branching import PP_node,PP_node_fairness, get_misclassification, get_split_values,get_misclassification_bag,get_misclassification_bag_sensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/elifrana/Desktop/OCT/n-depth'\n",
      "/Users/elranay/Desktop/FilesAll\n"
     ]
    }
   ],
   "source": [
    "cd /Users/elifrana/Desktop/OCT/n-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "# Define this directive to disable the deprecated NumPy API\n",
    "#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\n",
    "import numpy as np\n",
    "import copy\n",
    "from gurobipy import *\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from sklearn import preprocessing as pre\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import concurrent.futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_iteration_separator():\n",
    "    separator_length = 50\n",
    "    separator_char = '*'\n",
    "\n",
    "    separator_line = separator_char * separator_length\n",
    "    print(separator_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1423, 1784, 1671, ...,  543, 1211, 1597])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_shuffle_indices(n):\n",
    "    arr=np.arange(0,n)\n",
    "    np.random.shuffle(arr)\n",
    "    return arr\n",
    "\n",
    "def split_into_batches(data_x,data_y, n):\n",
    "    global indices\n",
    "    global batch_sizes\n",
    "    batch_size = len(data) // n\n",
    "    remainder = len(data) % n\n",
    "\n",
    "    start_idx = 0\n",
    "    batch_sizes=[]\n",
    "    for i in range(n):\n",
    "        batch_end = start_idx + batch_size + (1 if i < remainder else 0)\n",
    "        batch_sizes.append(batch_end-start_idx)\n",
    "        yield data_x[indices[start_idx:batch_end]],data_y[indices[start_idx:batch_end]]\n",
    "        start_idx = batch_end\n",
    "\n",
    "indices=get_shuffle_indices(2000)\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relpath=\"./Datasets/\"+dataset+\"/fold=\"+str(fold)+\"_train.csv\"\n",
    "data = pd.read_csv(relpath)#pd.read_csv(\"./Datasets/fold=1_train.csv\")\n",
    "\n",
    "\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,:1]\n",
    "\n",
    "\n",
    "\n",
    "P = [i for i in range(data.shape[1]-1)]\n",
    "K = list(data.y.unique())\n",
    "k=len(K)\n",
    "\n",
    "min_bucket_leaf= 0 # minimum number of data that should fall under each leaf\n",
    "D = list(range(d))\n",
    "N = list(range(X.shape[0]))\n",
    "n = len(N)\n",
    "n_leaves = 2**d\n",
    "p = X.shape[1]\n",
    "\n",
    "y_k = np.zeros((X.shape[0], len(K)))\n",
    "for k in range(len(K)):\n",
    "    y_k[np.where(y==K[k])[0],k] = 1\n",
    "\n",
    "y_k=y_k.astype(np.int32)\n",
    "x = np.array(X,dtype=np.int32)\n",
    "y_arr=np.array(y,dtype=np.int32).flatten()-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### transfer these to cython!    \n",
    "def get_alpha(pattern, j, level, split_values=None):\n",
    "    try:\n",
    "        if pattern[level] == j and split_values[level] == 1:\n",
    "            out = 1\n",
    "        else:\n",
    "            out = 0\n",
    "    except:\n",
    "        print(\"Incorrect pattern\")\n",
    "        print([pattern, j, level, split_values])\n",
    "        out = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "def get_beta(pattern, j, level, split_values):\n",
    "    try:\n",
    "        if pattern[level] == j and split_values[level] == 0:\n",
    "            out = 1\n",
    "        else:\n",
    "            out = 0\n",
    "    except:\n",
    "        print([pattern, j, level, split_values])\n",
    "        print(\"Incorrect pattern\")\n",
    "        out = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "#### transfer these to cython!    \n",
    "def get_alpha_beta(pattern, j, feature_split_condition):\n",
    "    \"\"\"\n",
    "    This function assumes that the pattern provided is a tuple of lists, with 0-split features being the second entry,\n",
    "    and 1-split features being the first entry. If the feature split condition matches the position of the feature,\n",
    "    the function returns one. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        if j in pattern[1-feature_split_condition]:\n",
    "            out = pattern[1-feature_split_condition].count(j)\n",
    "        else:\n",
    "            out = 0\n",
    "    except:\n",
    "        print(\"Incorrect pattern\")\n",
    "        print([pattern, j, feature_split_condition])\n",
    "        out = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## return the solution of the tree:\n",
    "### WRITE CODE HERE###\n",
    "## column generator function\n",
    "def get_column(leaf,d,pattern,p):\n",
    "    \"\"\" \n",
    "    Gives the column associated with a certain pattern. The column vector will have length 2^d + (2^(d+1))*p\n",
    "    Establishes the leaf's connection with all cousins, by order of closeness of cousin degrees.\n",
    "    The connections at one level are formed for each cousin pair by iterating each feature. This procedure is continued for each level in which the\n",
    "    pair continues to be associated with each other.\n",
    "\n",
    "    \"\"\"\n",
    "    global sensitive_features\n",
    "    my_column=np.zeros(2**d)\n",
    "    my_column[leaf]=1\n",
    "    \n",
    "    cons_list=[my_column]\n",
    "    start=leaf*2*p\n",
    "    leaf_cons=np.zeros(2**(d+1)*p)\n",
    "    for feature in range(p):\n",
    "        for split_condition in range(2): # binary split tree\n",
    "            leaf_cons[start+2*feature+split_condition]=-1*get_alpha_beta(pattern,feature,1-split_condition)\n",
    "    cons_list.append(leaf_cons)\n",
    "    fairness_cons=get_fairness_cons(leaf,pattern,sensitive_features) # 2* len(sensitive features)\n",
    "    cons_list.append(fairness_cons)\n",
    "    column=np.concatenate(cons_list)\n",
    "\n",
    "    return(column.reshape(len(column),1)) # appropriate column shape\n",
    "\n",
    "def get_w_columns(d,p):\n",
    "    \"\"\"\n",
    "    Takes tree depth and number of features p to return the w columns always present in the model.\n",
    "    The returned array can be joined horizontally with the pattern constraints.\n",
    "    Cython version exists, but is not in use.\n",
    "\n",
    "    \"\"\"\n",
    "    global sensitive_features\n",
    "    number_of_nodes= 2**(d)-1\n",
    "    len_w = number_of_nodes*p\n",
    "    len_cons=p*2**(d+1) ## binary splits\n",
    "    assignment_cons=np.zeros((2**d,len_w))\n",
    "    all_cons=[assignment_cons]\n",
    "    \n",
    "\n",
    "    for leaf in range(2**d):\n",
    "        \n",
    "\n",
    "        split_values=1-get_split_values(leaf,d).astype(int)\n",
    "        w_indices_for_leaf=[0]\n",
    "\n",
    "        ### obtain the leaf's association with split nodes\n",
    "        for d_temp in range(1,d):\n",
    "            values=np.arange(2**d_temp -1,2**d_temp -1 + 2**d_temp)\n",
    "            w_index=leaf//(2**(d-d_temp))\n",
    "            w_indices_for_leaf.append(values[w_index])\n",
    "\n",
    "\n",
    "        ### build the constraint set:\n",
    "        for feature_ in range(p):\n",
    "            feature_cons=[]\n",
    "            for node in range(number_of_nodes):\n",
    "                cons_temp=np.zeros((2,p))\n",
    "                if node in w_indices_for_leaf:\n",
    "                        index=w_indices_for_leaf.index(node)\n",
    "                        cons_temp[split_values[index],feature_]=1\n",
    "                feature_cons.append(cons_temp)\n",
    "\n",
    "            cons_leaf_feature=np.hstack(feature_cons)\n",
    "            all_cons.append(cons_leaf_feature)\n",
    "            \n",
    "    ### add fairness cons\n",
    "    all_cons.append(np.zeros((2*len(sensitive_features),len_w)))\n",
    "    all_cons=np.vstack(all_cons)\n",
    "    \n",
    "    return all_cons   \n",
    "        \n",
    "def get_fairness_cons(leaf,pattern,sensitive_features):\n",
    "    global n\n",
    "    global x\n",
    "\n",
    "    # returns the fairness constraint column for the pair, sensitive features are given as a list\n",
    "    sigma_list=[]\n",
    "    for feature in sensitive_features:\n",
    "        #n_group_sensitive=len(x[np.where(x[:,feature]==1)])\n",
    "        #n_group_nonsensitive=n-n_group_sensitive\n",
    "        info_sensitive, info_non_sensitive=get_misclassification_bag_sensitive(x, y_k, pattern, leaf,[feature])\n",
    "        #sigma= info_sensitive[0]/info_sensitive[1] if info_sensitive[1]> 0 else 0   - info_non_sensitive[0]/info_non_sensitive[1] if info_non_sensitive[1]>0 else 0\n",
    "        #sigma= (info_sensitive[0] - info_non_sensitive[0])/n#(info_sensitive[1]+info_non_sensitive[1]) if info_sensitive[1]+info_non_sensitive[1]> 0 else 0 \n",
    "        #sigma= (info_sensitive[0]*n_group_nonsensitive - info_non_sensitive[0]*n_group_sensitive)/(n_group_sensitive*n_group_nonsensitive)\n",
    "        sigma=(info_sensitive[0] - info_non_sensitive[0])/n\n",
    "        sigma_list.extend([sigma,-1*sigma])\n",
    "    column= np.array(sigma_list)\n",
    "    return column\n",
    "\n",
    "def get_w_indices(leaf):\n",
    "    \"\"\"\n",
    "    Cython version exists, but is not in use.\n",
    "    \"\"\"\n",
    "    # returns effected indices of each leaf\n",
    "    w_indices_for_leaf=[0]\n",
    "    ### obtain the leaf's association with split nodes\n",
    "    for d_temp in range(1,d):\n",
    "        values=np.arange(2**d_temp -1,2**d_temp -1 + 2**d_temp)\n",
    "        w_index=leaf//(2**(d-d_temp))\n",
    "        w_indices_for_leaf.append(values[w_index])\n",
    "\n",
    "    return w_indices_for_leaf\n",
    "\n",
    "def get_affected_leaves(node,w_indices_for_leaves):\n",
    "    \"\"\"\n",
    "    Cython version exists, but is not in use.\n",
    "    \"\"\"\n",
    "    affected_leaves=[]\n",
    "    ### obtain the leaf's association with split nodes\n",
    "\n",
    "    for leaf in range(len(w_indices_for_leaves)):\n",
    "        values=w_indices_for_leaves[leaf]\n",
    "        if node in values:\n",
    "            affected_leaves.append(leaf) \n",
    "\n",
    "    return affected_leaves\n",
    "\n",
    "def get_cousins(depth, leaf):\n",
    "    \"\"\"\n",
    "    returns a list of cousins ordered by their degree\n",
    "    \"\"\"\n",
    "    cousins=[[] for level in range(depth)]\n",
    "    cousins[depth-1]=[i for i in range(2**depth) if i!=leaf]\n",
    "    for i in range(depth-1,0,-1):\n",
    "        middle_split= leaf//2**(i)\n",
    "        cousins[i-1]=cousins[i][-(2**(i)-1):] if middle_split else cousins[i][:2**(i)-1] \n",
    "\n",
    "\n",
    "    return cousins\n",
    "\n",
    "\n",
    "\n",
    "def calculate_miss(x_tilde,y_tilde,j,RHS):\n",
    "    indices= x_tilde[:,j]==RHS\n",
    "    x_tilde_2= x_tilde[indices,:]\n",
    "    y_tilde_2= y_tilde[indices,:]\n",
    "    n_j= len(x_tilde_2)\n",
    "    count=np.sum(y_tilde_2,axis=0)\n",
    "    return n_j-np.max(count)\n",
    "\n",
    "def calculate_gini(x_tilde,y_tilde,j,RHS):\n",
    "    indices= x_tilde[:,j]==RHS\n",
    "    x_tilde_2= x_tilde[indices,:]\n",
    "    y_tilde_2= y_tilde[indices,:]\n",
    "    n_j= len(x_tilde_2) # number of data points\n",
    "    count=np.sum(y_tilde_2,axis=0) #number of ones and zeros\n",
    "    gini= 1-np.sum(np.square((count/n_j))) #1- sum(p^2) -- sum over classes\n",
    "    return gini\n",
    "\n",
    "from more_itertools import distinct_permutations\n",
    "from itertools import product,combinations,combinations_with_replacement\n",
    "\n",
    "\n",
    "\n",
    "def find_all_bags(feature_num,leaf,d):\n",
    "    \"\"\"\n",
    "    takes number of features and returns all possible bag combinations\n",
    "    includes repeats\n",
    "    \"\"\"\n",
    "    split_values=get_split_values(leaf,d)\n",
    "    max_num=int(np.sum(split_values))\n",
    "    input_list=np.arange(feature_num)\n",
    "    input_set = set(input_list)\n",
    "    result_tuples = []\n",
    "\n",
    "    \n",
    "    for i in combinations_with_replacement(input_list, max_num):\n",
    "        list1 = list(i) # 1 features\n",
    "        set_temp1=set(list1)\n",
    "        set2= input_list#list(input_set-set(i)) # 0 features  #### either enable or disable selecting a feature as both 0 and 1 # input_set\n",
    "        for j in combinations_with_replacement(set2, d-max_num):\n",
    "            list2 = list(j)  # 0 features\n",
    "            set_temp2=set(list2)\n",
    "            \n",
    "            result_tuples.append((list1, list2))\n",
    "    \n",
    "    return result_tuples\n",
    "\n",
    "def find_all_bags_fixed_feature(feature_num,leaf,d,fixed_feature_info):\n",
    "    \"\"\"\n",
    "    takes number of features and returns all possible bag combinations\n",
    "    includes repeats\n",
    "    uses the fixed feature (given in a list of tuples)\n",
    "    \"\"\"\n",
    "    # we have to not use the features above!\n",
    "    \n",
    "    split_values=get_split_values(leaf,d)\n",
    "    #dont_use=set(fixed_feature_info[fixed_feature_info[:,-1]==0][:,1].tolist()) # get non-used features for splits\n",
    "    fixed_all=fixed_feature_info[fixed_feature_info[:,-1]==1].tolist() # get the fixed features\n",
    "\n",
    "    input_list=np.arange(feature_num)\n",
    "    input_set = set(input_list)#s-dont_use\n",
    "    \n",
    "    result_tuples = []\n",
    "    \n",
    "    for condition in set(get_split_values(leaf,d).astype(int)):\n",
    "\n",
    "        fixed_pattern_template=([],[])\n",
    "        counters=[0,0]\n",
    "    \n",
    "\n",
    "        for fixed in fixed_all:\n",
    "            feature=fixed[0]\n",
    "            #w_index=fixed[0]\n",
    "            #depth_affected=w_indices.index(w_index)\n",
    "            #condition= get_split_values(leaf,d).astype(int)[depth_affected]\n",
    "            fixed_pattern_template[1-condition].append(feature)\n",
    "            counters[1-condition]+=1\n",
    "            max_num=int(np.sum(split_values))-counters[0]\n",
    "\n",
    "            # for every possible split use case!\n",
    "            for i in combinations_with_replacement(input_set, max_num):\n",
    "                list1 = list(i) # 1 features\n",
    "                set_temp1=set(list1)\n",
    "                set2= input_set#list(input_set-set(i)) # 0 features  #### either enable or disable selecting a feature as both 0 and 1 # input_set\n",
    "                for j in combinations_with_replacement(set2, d-max_num-sum(counters)):\n",
    "                    list2 = list(j)  # 0 features\n",
    "                    set_temp2=set(list2)\n",
    "                    result_tuples.append((list1+fixed_pattern_template[0], list2+fixed_pattern_template[1])) # add the fixed feature\n",
    "    \n",
    "    return result_tuples\n",
    "\n",
    "def find_all_repeating_bags(feature_num,leaf,d):\n",
    "    \"\"\"\n",
    "    takes number of features and returns all possible bag combinations\n",
    "    includes repeats\n",
    "    \"\"\"\n",
    "    split_values=get_split_values(leaf,d)\n",
    "    max_num=int(np.sum(split_values))\n",
    "    input_list=np.arange(feature_num)\n",
    "    input_set = set(input_list)\n",
    "    result_tuples = []\n",
    "\n",
    "    \n",
    "    for i in combinations_with_replacement(input_list, max_num):\n",
    "        list1 = list(i) # 1 features\n",
    "        set2 = input_set #list(input_set-set(i)) # 0 features\n",
    "        set_temp1=set(list1)\n",
    "    \n",
    "            \n",
    "\n",
    "        for j in combinations_with_replacement(set2, d-max_num):\n",
    "            list2 = list(j)  # 0 features\n",
    "            set_temp2=set(list2)\n",
    "\n",
    "            if (len(set_temp1)!=len(list1) or len(set_temp2)!=len(list2)) or len(set_temp1.intersection(set_temp2)) >0: #and len(set_temp1.intersection(set_temp2)) ==0: ### for prohibiting invalid patterns #\n",
    "                ## repeating check and valid check\n",
    "                result_tuples.append((list1, list2))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return result_tuples\n",
    "\n",
    "#Cythonized version exists\n",
    "\"\"\"\n",
    "def get_miss_bag(pattern_bag,leaf,x,y_k):\n",
    "    # pattern_bag includes a tuple of lists\n",
    "    global d\n",
    "    splits=1-get_split_values(leaf,d).astype(int)\n",
    "\n",
    "    pattern=[] #[0] \n",
    "\n",
    "    counter=np.zeros(2,dtype=np.int32)\n",
    "    #[[0, 0], []]\n",
    "    for split_condition in splits:\n",
    "        try:\n",
    "            pattern.append(pattern_bag[split_condition][counter[split_condition]])\n",
    "            counter[split_condition]+=1\n",
    "        except: # a feature is repeated for branching\n",
    "            pattern.append(pattern_bag[split_condition][counter[split_condition]-1])\n",
    "        \n",
    "  \n",
    "    return get_misclassification(x, y_k, np.array(pattern,dtype=np.int32), leaf)\n",
    "\"\"\"\n",
    "# Define a custom sorting key\n",
    "def custom_sort(item):\n",
    "    return (len(item[0]), len(item[1]))\n",
    "\n",
    "\n",
    "def get_shuffle_indices(n):\n",
    "    arr=np.arange(0,n)\n",
    "    np.random.shuffle(arr)\n",
    "    return arr\n",
    "\n",
    "def split_into_batches(data_x,data_y, n):\n",
    "    global indices\n",
    "    global batch_sizes\n",
    "    batch_size = len(data) // n\n",
    "    remainder = len(data) % n\n",
    "\n",
    "    start_idx = 0\n",
    "    batch_sizes=[]\n",
    "    for i in range(n):\n",
    "        batch_end = start_idx + batch_size + (1 if i < remainder else 0)\n",
    "        batch_sizes.append(batch_end-start_idx)\n",
    "        yield data_x[indices[start_idx:batch_end]],data_y[indices[start_idx:batch_end]]\n",
    "        start_idx = batch_end\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching for Pricing Problems Using Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Patterns List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empty patterns should be detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of all patterns that are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### generate all tuples and randomly add to the initial set\n",
    "###### NEW PATTERN DEFINITION ####\n",
    "np.random.seed(42)# set seed (also restart seed!)\n",
    "\n",
    "### add one level splits!\n",
    "#### store the set of all patterns\n",
    "# Sort the couples list using the custom key\n",
    "all_patterns_list=[find_all_bags(p,leaf,d) for leaf in range(2**d)]\n",
    "all_patterns_list_sorted=[sorted(all_patterns_list[leaf], key=custom_sort) for leaf in range(2**d)]\n",
    "all_repeating_patterns_list=[find_all_repeating_bags(p,leaf,d) for leaf in range(2**d)] # ensure repeats\n",
    "\n",
    "_=[np.random.shuffle(all_repeating_patterns_list[leaf])for leaf in range(2**d)]\n",
    "pattern_list= [all_repeating_patterns_list[leaf][:len(all_patterns_list[leaf])//10**(d-1)] for leaf in range(2**d)] # add a fraction of repeating patterns\n",
    "\n",
    "_=[np.random.shuffle(all_patterns_list[leaf])for leaf in range(2**d)]\n",
    "_=[pattern_list[leaf].extend(all_patterns_list[leaf][:len(all_patterns_list[leaf])//10**(d-1)]) for leaf in range(2**d)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patterns_initial=np.sum([len(pattern_list[i]) for i in range(2**d)])\n",
    "num_patterns_all=np.sum([len(all_patterns_list[i]) for i in range(2**d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all valid patterns: 2054\n"
     ]
    }
   ],
   "source": [
    "print('Number of all valid patterns:',num_patterns_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_list: [[([8, 8], []), ([16, 16], []), ([0, 0], []), ([24, 24], []), ([11, 11], []), ([9, 9], []), ([13, 13], []), ([1, 1], []), ([23, 23], []), ([5, 5], []), ([2, 2], []), ([12, 12], []), ([15, 15], []), ([3, 3], []), ([4, 4], []), ([21, 21], []), ([17, 17], []), ([22, 22], []), ([18, 18], []), ([25, 25], []), ([20, 20], []), ([7, 7], []), ([10, 10], []), ([14, 14], []), ([19, 19], []), ([6, 6], []), ([16, 23], []), ([1, 14], []), ([21, 25], []), ([10, 13], []), ([6, 20], []), ([9, 10], []), ([7, 18], []), ([4, 7], []), ([3, 16], []), ([1, 5], []), ([2, 23], []), ([7, 14], []), ([5, 25], []), ([2, 15], []), ([8, 18], []), ([2, 6], []), ([15, 24], []), ([14, 25], []), ([20, 20], []), ([3, 10], []), ([3, 5], []), ([5, 17], []), ([10, 22], []), ([4, 23], []), ([10, 15], []), ([17, 19], []), ([3, 7], []), ([5, 6], []), ([0, 9], []), ([14, 16], []), ([4, 11], []), ([12, 14], []), ([2, 9], []), ([4, 19], []), ([2, 22], [])], [([18], [18]), ([10], [10]), ([7], [7]), ([12], [12]), ([24], [24]), ([5], [5]), ([17], [17]), ([0], [0]), ([3], [3]), ([1], [1]), ([13], [13]), ([8], [8]), ([20], [20]), ([6], [6]), ([22], [22]), ([4], [4]), ([2], [2]), ([23], [23]), ([19], [19]), ([14], [14]), ([15], [15]), ([9], [9]), ([16], [16]), ([25], [25]), ([21], [21]), ([11], [11]), ([6], [2]), ([10], [9]), ([11], [5]), ([20], [18]), ([14], [3]), ([6], [1]), ([4], [24]), ([2], [4]), ([17], [6]), ([16], [6]), ([13], [17]), ([3], [9]), ([6], [4]), ([4], [11]), ([24], [22]), ([19], [3]), ([17], [5]), ([10], [3]), ([22], [5]), ([23], [5]), ([15], [10]), ([24], [19]), ([3], [8]), ([22], [1]), ([18], [14]), ([1], [18]), ([10], [8]), ([11], [6]), ([10], [17]), ([18], [20]), ([4], [15]), ([12], [6]), ([9], [10]), ([21], [12]), ([16], [13]), ([0], [23]), ([13], [24]), ([12], [1]), ([5], [17]), ([19], [20]), ([23], [0]), ([13], [4]), ([3], [18]), ([18], [12]), ([0], [1]), ([4], [5]), ([11], [12]), ([9], [9]), ([17], [11]), ([13], [5]), ([25], [15]), ([12], [19]), ([3], [23]), ([7], [16]), ([1], [0]), ([13], [23]), ([3], [25]), ([9], [8]), ([7], [17]), ([23], [23]), ([17], [19]), ([4], [23]), ([1], [25]), ([4], [18]), ([21], [16]), ([2], [18]), ([14], [13])], [([15], [15]), ([21], [21]), ([12], [12]), ([17], [17]), ([4], [4]), ([8], [8]), ([25], [25]), ([10], [10]), ([9], [9]), ([5], [5]), ([16], [16]), ([18], [18]), ([23], [23]), ([24], [24]), ([3], [3]), ([0], [0]), ([13], [13]), ([2], [2]), ([22], [22]), ([7], [7]), ([11], [11]), ([6], [6]), ([14], [14]), ([19], [19]), ([1], [1]), ([20], [20]), ([7], [1]), ([25], [8]), ([20], [12]), ([18], [5]), ([25], [16]), ([7], [13]), ([17], [23]), ([6], [10]), ([8], [12]), ([18], [20]), ([23], [0]), ([10], [4]), ([5], [1]), ([12], [3]), ([11], [19]), ([14], [14]), ([2], [13]), ([15], [9]), ([9], [23]), ([19], [2]), ([1], [16]), ([15], [24]), ([5], [4]), ([0], [9]), ([14], [18]), ([3], [4]), ([11], [12]), ([17], [6]), ([13], [13]), ([25], [21]), ([6], [0]), ([21], [5]), ([3], [15]), ([12], [23]), ([16], [24]), ([5], [5]), ([25], [3]), ([24], [22]), ([19], [12]), ([23], [6]), ([12], [7]), ([20], [4]), ([24], [25]), ([14], [12]), ([9], [7]), ([23], [19]), ([24], [0]), ([1], [3]), ([18], [11]), ([8], [24]), ([22], [18]), ([4], [16]), ([8], [16]), ([17], [17]), ([4], [5]), ([8], [4]), ([19], [22]), ([12], [12]), ([19], [8]), ([11], [3]), ([9], [22]), ([12], [6]), ([7], [9]), ([8], [5]), ([16], [6]), ([16], [11]), ([21], [3])], [([], [17, 17]), ([], [22, 22]), ([], [2, 2]), ([], [5, 5]), ([], [0, 0]), ([], [25, 25]), ([], [6, 6]), ([], [19, 19]), ([], [10, 10]), ([], [8, 8]), ([], [23, 23]), ([], [16, 16]), ([], [20, 20]), ([], [24, 24]), ([], [12, 12]), ([], [4, 4]), ([], [18, 18]), ([], [21, 21]), ([], [7, 7]), ([], [14, 14]), ([], [15, 15]), ([], [13, 13]), ([], [3, 3]), ([], [9, 9]), ([], [1, 1]), ([], [11, 11]), ([], [3, 6]), ([], [4, 9]), ([], [3, 19]), ([], [9, 9]), ([], [20, 20]), ([], [4, 14]), ([], [13, 17]), ([], [13, 25]), ([], [2, 11]), ([], [15, 21]), ([], [1, 16]), ([], [3, 18]), ([], [13, 22]), ([], [5, 16]), ([], [13, 13]), ([], [2, 8]), ([], [2, 17]), ([], [7, 25]), ([], [12, 12]), ([], [4, 8]), ([], [1, 6]), ([], [9, 20]), ([], [20, 22]), ([], [1, 25]), ([], [12, 17]), ([], [6, 10]), ([], [0, 16]), ([], [14, 19]), ([], [13, 23]), ([], [1, 4]), ([], [7, 19]), ([], [10, 21]), ([], [9, 16]), ([], [6, 22]), ([], [7, 12])]]\n"
     ]
    }
   ],
   "source": [
    "print(\"pattern_list:\",pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### instance log\n",
    "relpath=\"./Datasets/\"+dataset+\"/fold=\"+str(fold)\n",
    "filename=relpath+'_instance_log_'+str(d)+'.txt'\n",
    "with open(filename, 'w') as file:\n",
    "    K = list(data.y.unique())\n",
    "    texts=[str(n),str(p),str(num_patterns_all),str(len(K))]\n",
    "    separator = \",\"\n",
    "    data = separator.join(texts)\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_partial_OCT_IP_matrix(pattern_list, x, y_k, d,p):\n",
    "    global n\n",
    "    global epsilon\n",
    "    global cons_time\n",
    "    timer_start=time.time()\n",
    "    ### Baseline model\n",
    "    ## the W variables coefficients will be filled before column generation\n",
    "    cons_basis= get_w_columns(d,p)\n",
    "    \n",
    "    \n",
    "    ### get A matrix ###\n",
    "    columns = [cons_basis]\n",
    "    _ = [\n",
    "        [columns.append(get_column(leaf,d, pattern, p)) for leaf in range(len(pattern_list)) for pattern in pattern_list[leaf]]    \n",
    "    ] # null list to hide extend output\n",
    "\n",
    "    miss_and_count=[get_misclassification_bag(x, y_k, pattern_bag, leaf) for leaf in np.arange(len(pattern_list),dtype=np.int32) for pattern_bag in pattern_list[leaf]]\n",
    "    \n",
    "    ### MISSS function change here\n",
    "    \n",
    "    A= np.concatenate(columns,axis=1)\n",
    "\n",
    "\n",
    "    ### get b ###\n",
    "    b = np.concatenate([np.ones(len(pattern_list)),np.zeros(len(A)-len(pattern_list)-2*len(sensitive_features)),np.ones(2*len(sensitive_features))*epsilon]) # RHS\n",
    "    \n",
    "    ### get c ###\n",
    "\n",
    "    c=np.array([miss_and_count[i][0]/n for i in range(len(miss_and_count))])\n",
    "    c=np.concatenate([np.zeros(cons_basis.shape[1]),c]) ### add 0 obj for w\n",
    "    \n",
    "    ### build model ###\n",
    "\n",
    "    mp = Model('MasterProblemLP')\n",
    "    #mp.setParam('OutputFlag', 0)\n",
    "    \n",
    "    mp.setParam('TimeLimit', 10800)\n",
    "\n",
    "    # add as many variables as the number of patterns\n",
    "    mp.addMVar(A.shape[1]-len(miss_and_count), vtype=GRB.BINARY,name='w') \n",
    "    mp.addMVar(len(miss_and_count), vtype=GRB.BINARY,name='pattern') \n",
    "    signs=['=',]*(len(A)-2*len(sensitive_features)) + ['<']*(2*len(sensitive_features)) # fairness signs\n",
    "    mp.addMConstr(A, None, signs , b) # change here as well\n",
    "\n",
    "    #sp.setMObjective(None,c_new,0,None,None,None,GRB.MAXIMIZE)\n",
    "    mp.setMObjective(None, c, 0.0, xQ_L=None, xQ_R=None, xc=None, sense=GRB.MINIMIZE )\n",
    "\n",
    "    timer_end=time.time()\n",
    "    cons_time=timer_end-timer_start\n",
    "\n",
    "    timer_start=time.time()\n",
    "    mp.optimize()\n",
    "    timer_end=time.time()\n",
    "    return mp, A, b, c,timer_end-timer_start\n",
    "\n",
    "def solve_partial_OCT_matrix(pattern_list, x, y_k, d,p):\n",
    "    global n\n",
    "    \n",
    "    ### Baseline model\n",
    "    ## the W variables coefficients will be filled before column generation\n",
    "    cons_basis= get_w_columns(d,p)\n",
    "    \n",
    "    \n",
    "    ### get A matrix ###\n",
    "    columns = [cons_basis]\n",
    "    _ = [\n",
    "        [columns.append(get_column(leaf,d, pattern, p)) for leaf in range(len(pattern_list)) for pattern in pattern_list[leaf]]    \n",
    "    ] # null list to hide extend output\n",
    "\n",
    "    miss_and_count=[get_misclassification_bag(x, y_k, pattern_bag, leaf) for leaf in np.arange(len(pattern_list),dtype=np.int32) for pattern_bag in pattern_list[leaf]]\n",
    "    \n",
    "    ### MISSS function change here\n",
    "    \n",
    "    A= np.concatenate(columns,axis=1)\n",
    "\n",
    "\n",
    "    ### get b ###\n",
    "    b = np.concatenate([np.ones(len(pattern_list)),np.zeros(len(A)-len(pattern_list)-2),np.ones(2*len(sensitive_features))*epsilon]) # RHS\n",
    "    \n",
    "    ### get c ###\n",
    "\n",
    "    c=np.array([miss_and_count[i][0]/n for i in range(len(miss_and_count))])\n",
    "    c=np.concatenate([np.zeros(cons_basis.shape[1]),c]) ### add 0 obj for w\n",
    "    \n",
    "    ### build model ###\n",
    "\n",
    "    mp = Model('MasterProblemLP')\n",
    "    mp.setParam('OutputFlag', 0)\n",
    "    \n",
    "    # add as many variables as the number of patterns\n",
    "    mp.addMVar(A.shape[1]-len(miss_and_count), vtype=GRB.CONTINUOUS,name='w',lb=0) \n",
    "    mp.addMVar(len(miss_and_count), vtype=GRB.CONTINUOUS,name='pattern',lb=0) \n",
    "\n",
    "    signs=['=',]*(len(A)-2) + ['<']*2 # fairness signs\n",
    "    mp.addMConstr(A, None, signs , b)\n",
    "\n",
    "    #sp.setMObjective(None,c_new,0,None,None,None,GRB.MAXIMIZE)\n",
    "    mp.setMObjective(None, c, 0.0, xQ_L=None, xQ_R=None, xc=None, sense=GRB.MINIMIZE )\n",
    "    mp.optimize()\n",
    "\n",
    "    return mp, A, b, c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dual_partial_OCT_matrix(A,b,c):\n",
    "    ### build model ###\n",
    "    dual_mp=Model('Dual')\n",
    "\n",
    "    dual_mp.setParam('OutputFlag', 0)\n",
    "    \n",
    "    # add as many variables as the number of constraints\n",
    "    dual_mp.addMVar(A.shape[0], vtype=GRB.CONTINUOUS,ub=GRB.INFINITY,lb=-GRB.INFINITY,name='pattern') \n",
    "\n",
    "    dual_mp.addMConstr(A.T, None, '<' , c)\n",
    "\n",
    "    #sp.setMObjective(None,c_new,0,None,None,None,GRB.MAXIMIZE)\n",
    "    dual_mp.setMObjective(None, b, 0.0, xQ_L=None, xQ_R=None, xc=None, sense=GRB.MAXIMIZE )\n",
    "    dual_mp.optimize()\n",
    "\n",
    "    return dual_mp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m,A,b,c=solve_partial_OCT_matrix(all_patterns_list, x, y_k, d,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.objval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m,A,b,c,_=solve_partial_OCT_IP_matrix(all_patterns_list, x, y_k, d,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.ObjVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printIPVars(IP_model):\n",
    "    # Print non-zero decision variables, HERE BOTH PATTERN NUMBER AND LEAF NUMBER STARTS FROM 0\n",
    "    pattern_counter=[0,]*(2**(d))\n",
    "    leaf_pointer_array=IP_model.getA()[:2**(d)].toarray()\n",
    "    for i, var in enumerate(IP_model.X):\n",
    "            leaf=np.where((leaf_pointer_array[:,i]==1))[0][0]    \n",
    "            if var > 0:\n",
    "                index= pattern_counter[leaf]\n",
    "                print(f'Leaf {leaf+1} pattern {index+ 1}: {var}')\n",
    "                print('pattern:',all_patterns_list[leaf][index])\n",
    "            pattern_counter[leaf]+=1 #update index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_unraveled=[]\n",
    "#_=[list_unraveled.extend(all_patterns_list[l]) for l in range(2**d)]\n",
    "#indices=np.where(np.array(m.X)[(2**d-1)*p:])[0]\n",
    "#for i in indices:\n",
    "#    print(list_unraveled[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively extract split features\n",
    "def extract_split_features(d,tree_structure,leaf):\n",
    "    \"\"\"\n",
    "    Node: 0,1,2,...2**d-1\n",
    "    \"\"\"\n",
    "    empty_pattern=tuple([[] for _ in range(2)])\n",
    "    nodes=get_w_indices(2**d-leaf-1) # we are doing this because CART builder assumes right splits are postive and left are negative\n",
    "    splits=get_split_values(leaf,d).astype(int)\n",
    "    tree_features=tree_structure.feature[tree_structure.feature>=0]\n",
    "    for node in nodes:\n",
    "        feature_new = tree_features[node] if node<len(tree_features) else -1\n",
    "        level=0#(node+1)//(2**(d-1))\n",
    "        flag=node in np.arange(2**level-1,2**(level+1)-1).tolist()\n",
    "        while not flag:\n",
    "            level+=1\n",
    "            flag=node in np.arange(2**level-1,2**(level+1)-1).tolist()\n",
    "            \n",
    "        empty_pattern[1-splits[level]].append(feature_new) if feature_new >=0 else empty_pattern[1-splits[level]].append(feature_old)\n",
    "        feature_old=feature_new # store this split\n",
    "    \n",
    "    return empty_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Miss: 0.23756858710562412\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "clf = tree.DecisionTreeClassifier(max_depth=d)\n",
    "clf = clf.fit(x, y)\n",
    "prediction = clf.predict(x)\n",
    "cart_acc=1-accuracy_score(y,prediction)\n",
    "print('CART Miss:',cart_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.6, 0.8333333333333334, 'x[23] <= 0.5\\ngini = 0.682\\nsamples = 11664\\nvalue = [3888.0, 3840.0, 1.0, 3640.0, 295.0]'),\n",
       " Text(0.4, 0.5, 'x[8] <= 0.5\\ngini = 0.536\\nsamples = 7776\\nvalue = [0, 3840, 1, 3640, 295]'),\n",
       " Text(0.5, 0.6666666666666667, 'True  '),\n",
       " Text(0.2, 0.16666666666666666, 'gini = 0.52\\nsamples = 6237\\nvalue = [0, 3653, 1, 2288, 295]'),\n",
       " Text(0.6, 0.16666666666666666, 'gini = 0.213\\nsamples = 1539\\nvalue = [0, 187, 0, 1352, 0]'),\n",
       " Text(0.8, 0.5, 'gini = 0.0\\nsamples = 3888\\nvalue = [3888, 0, 0, 0, 0]'),\n",
       " Text(0.7, 0.6666666666666667, '  False')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('CART Result')\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store incumbent CART patterns\n",
    "inc_patterns_CART=[[extract_split_features(d,clf.tree_,leaf)] for leaf in range(2**d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add cart patterns to assoc. pattern list\n",
    "_=[pattern_list[l].append(inc_patterns_CART[l][0]) for l in range(2**d)]\n",
    "_=[all_patterns_list[l].append(inc_patterns_CART[l][0]) for l in range(2**d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the IP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving IP Model\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-08-26\n",
      "Set parameter TimeLimit to value 10800\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (mac64[arm] - Darwin 24.2.0 24C101)\n",
      "\n",
      "CPU model: Apple M3 Pro\n",
      "Thread count: 11 physical cores, 11 logical processors, using up to 11 threads\n",
      "\n",
      "Optimize a model with 214 rows, 2136 columns and 10131 nonzeros\n",
      "Model fingerprint: 0x6e35a38a\n",
      "Variable types: 0 continuous, 2136 integer (2136 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+00]\n",
      "  Objective range  [8e-04, 5e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 53 rows and 4 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 161 rows, 2132 columns, 6917 nonzeros\n",
      "Variable types: 0 continuous, 2132 integer (2132 binary)\n",
      "Found heuristic solution: objective 0.2904664\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 30 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   10    0.29047    0.00000   100%     -    0s\n",
      "     0     0    0.12440    0   24    0.29047    0.12440  57.2%     -    0s\n",
      "     0     0    0.13609    0   25    0.29047    0.13609  53.1%     -    0s\n",
      "     0     0    0.14163    0   24    0.29047    0.14163  51.2%     -    0s\n",
      "     0     0    0.14373    0   12    0.29047    0.14373  50.5%     -    0s\n",
      "     0     0    0.14378    0   12    0.29047    0.14378  50.5%     -    0s\n",
      "     0     0    0.14503    0   24    0.29047    0.14503  50.1%     -    0s\n",
      "     0     0    0.14523    0   10    0.29047    0.14523  50.0%     -    0s\n",
      "H    0     0                       0.2491427    0.14523  41.7%     -    0s\n",
      "     0     0    0.19654    0   19    0.24914    0.19654  21.1%     -    0s\n",
      "H    0     1                       0.2375686    0.19654  17.3%     -    0s\n",
      "\n",
      "Explored 1 nodes (279 simplex iterations) in 0.04 seconds (0.05 work units)\n",
      "Thread count was 11 (of 11 available processors)\n",
      "\n",
      "Solution count 3: 0.237569 0.249143 0.290466 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.375685871056e-01, best bound 2.375685871056e-01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "print('Solving IP Model')\n",
    "IP_model=solve_partial_OCT_IP_matrix(all_patterns_list, x, y_k, d,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printIPVars(IP_model):\n",
    "    # Print non-zero decision variables, HERE BOTH PATTERN NUMBER AND LEAF NUMBER STARTS FROM 0\n",
    "    inc_patterns=[[] for leaf in range(2**d)]\n",
    "    pattern_counter=[0,]*(2**(d))\n",
    "    leaf_pointer_array=IP_model[0].getA()[:2**(d)].toarray()\n",
    "    for i, var in enumerate(IP_model[0].X[(2**d-1)*p:]):\n",
    "            leaf=np.where((leaf_pointer_array[:,(2**d-1)*p+i]==1))[0][0]    \n",
    "            if var > 0:\n",
    "                index= pattern_counter[leaf]\n",
    "                print(f'Leaf {leaf+1} pattern {index+ 1}: {var}')\n",
    "                print('pattern:',all_patterns_list[leaf][index])\n",
    "                inc_patterns[leaf].append(all_patterns_list[leaf][index])\n",
    "            pattern_counter[leaf]+=1 #update index\n",
    "    return inc_patterns\n",
    "\n",
    "def get_ODM(inc_patterns,d,x,y_k):\n",
    "    global sensitive_features\n",
    "    n= len(x)\n",
    "    ODM=0\n",
    "    for feature in sensitive_features:\n",
    "        ODM_feat_p=0\n",
    "        ODM_feat_m=0\n",
    "\n",
    "        for leaf in range(2**d):\n",
    "            info_sensitive, info_non_sensitive=get_misclassification_bag_sensitive(x, y_k, inc_patterns[leaf][0], leaf,[feature])\n",
    "            #sigma= info_sensitive[0]/info_sensitive[1] if info_sensitive[1]> 0 else 0   - info_non_sensitive[0]/info_non_sensitive[1]>0 if info_non_sensitive[1]>0 else 0\n",
    "            sigma= (info_sensitive[0] - info_non_sensitive[0])/(n)#/(info_sensitive[1]+info_non_sensitive[1]) if info_sensitive[1]+info_non_sensitive[1]> 0 else 0 \n",
    "            ODM_feat_p+=sigma\n",
    "            ODM_feat_m-=sigma\n",
    "        ODM=max(ODM,max(ODM_feat_p,ODM_feat_m))\n",
    "    return ODM\n",
    "\n",
    "def get_DCM(inc_patterns,d,x,y_k):\n",
    "    global sensitive_features\n",
    "    global K\n",
    "    DCM=0\n",
    "    \n",
    "    for classOfInterest in range(len(K)):\n",
    "        for feature in sensitive_features:\n",
    "                DCM_feat_class=0\n",
    "                for leaf in range(2**d):\n",
    "                    info_sensitive, info_non_sensitive=get_misclassification_bag_sensitive_class(x, y_k, inc_patterns[leaf][0], leaf,[feature],classOfInterest)\n",
    "                    #print(info_sensitive)\n",
    "                    #sigma= info_sensitive[0]/info_sensitive[1] if info_sensitive[1]> 0 else 0   - info_non_sensitive[0]/info_non_sensitive[1]>0 if info_non_sensitive[1]>0 else 0\n",
    "                    sigma= (info_sensitive[0] - info_non_sensitive[0])/np.sum(y_k[:,classOfInterest])#/(info_sensitive[1]+info_non_sensitive[1]) if info_sensitive[1]+info_non_sensitive[1]> 0 else 0 \n",
    "                    DCM_feat_class+=abs(sigma)\n",
    "                    #print(sigma)\n",
    "                DCM=max(DCM,DCM_feat_class)\n",
    "        return DCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf 1 pattern 134: 1.0\n",
      "pattern: ([8, 23], [])\n",
      "Leaf 2 pattern 228: 1.0\n",
      "pattern: ([8], [23])\n",
      "Leaf 3 pattern 320: 1.0\n",
      "pattern: ([23], [8])\n",
      "Leaf 4 pattern 51: 1.0\n",
      "pattern: ([], [8, 23])\n"
     ]
    }
   ],
   "source": [
    "inc_patterns_IP=printIPVars(IP_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP Model Objective: 0.23756858710562415\n",
      "IP Model Optimization Time: 0.0414738655090332\n"
     ]
    }
   ],
   "source": [
    "print('IP Model Objective:', IP_model[0].objval)\n",
    "print('IP Model Optimization Time:',IP_model[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP Model Train ODM: 0.29183813443072704\n"
     ]
    }
   ],
   "source": [
    "IP_ODM=get_ODM(inc_patterns_IP,d,x,y_k)\n",
    "print('IP Model Train ODM:',IP_ODM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "relpath=\"./Datasets/\"+dataset+\"/fold=\"+str(fold)+\"_test.csv\"\n",
    "data = pd.read_csv(relpath)#pd.read_csv(\"./Datasets/fold=1_train.csv\")\n",
    "\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,:1]\n",
    "\n",
    "y_k = np.zeros((X.shape[0], len(K)))\n",
    "for k in range(len(K)):\n",
    "    y_k[np.where(y==K[k])[0],k] = 1\n",
    "\n",
    "y_k=y_k.astype(np.int32)\n",
    "x = np.array(X,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_mis(inc_patterns,d,x,y_k):\n",
    "    miss=0\n",
    "    for leaf in range(2**d):\n",
    "        miss+=get_misclassification_bag(x, y_k, inc_patterns[leaf][0], leaf)[0]\n",
    "    return miss/len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_IP=get_tree_mis(inc_patterns_IP,d,x,y_k)\n",
    "IP_test_ODM=get_ODM(inc_patterns_IP,d,x,y_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP Test Accuracy Score is: 0.7723765432098766\n"
     ]
    }
   ],
   "source": [
    "print('IP Test Accuracy Score is:', 1-miss_IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Accuracy\n",
    "#Test Accuracy\n",
    "#Time\n",
    "#Opt Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP Model Objective: 0.23756858710562415\n",
      "IP Model Optimization Time: 0.0414738655090332\n"
     ]
    }
   ],
   "source": [
    "print('IP Model Objective:', IP_model[0].objval)\n",
    "print('IP Model Optimization Time:',IP_model[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_MIP=np.array([epsilon,cons_time,IP_model[-1],1-IP_model[0].objval,IP_ODM,IP_model[0].MIPGap, 1-miss_IP,IP_test_ODM])\n",
    "labels=np.array(['Epsilon','Cons_Time','Time','Train Accuracy','Train ODM','Opt Gap','Test Accuracy', 'Test ODM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_final=np.vstack([labels,res_MIP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Epsilon', 'Cons_Time', 'Time', 'Train Accuracy', 'Train ODM',\n",
       "        'Opt Gap', 'Test Accuracy', 'Test ODM'],\n",
       "       ['1.0', '1.3160450458526611', '0.0414738655090332',\n",
       "        '0.7624314128943759', '0.29183813443072704', '0.0',\n",
       "        '0.7723765432098766', '0.3055555555555556']], dtype='<U32')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "relpath=\"./Datasets/\"+dataset+\"/fold=\"+str(fold)\n",
    "np.savetxt(relpath+'_res_'+str(d)+'_Fairness_IP_Analysis_'+str(sensitive_features)+'_'+str(epsilon)+'.txt',res_final,fmt='%s',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open(relpath+'_DecisionRules_FairnessIP_'+str(d)+'.txt', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "print(inc_patterns_IP)\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Anaconda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6f27239ee5173af89586d909bd5305cea6834bd56882853a6f24792033a6314"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
